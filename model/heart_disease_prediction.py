# -*- coding: utf-8 -*-
"""Heart_Disease_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1giAJzjE3-u8HyG6yzEXcsPLJTKGZk-T_

#Heart Disease Prediction

Dataset: https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease?resource=download
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import joblib


path = 'https://raw.githubusercontent.com/absiddik7/Datasets/main/heart_2020_cleaned.csv'
df = pd.read_csv(path)
df_c = df.copy() # keep a copy of the df

df.head()

df.info()

"""##Exploratory Data Analysis

###Heart Disease Distribution
"""

disease = df.groupby('HeartDisease').size()
disease

sns.set_style('darkgrid')
plt.figure(figsize=(10,6))
plt.pie(disease,labels=['No', 'Yes'],autopct='%1.1f%%', textprops={"fontsize": 14})
plt.title('Hear Disease')

"""**Insights**


*   Most of the people don't have heart disease
*   Dataset is highly imbalanced

**Gender Distribution**
"""

sns.set_style('darkgrid')
sns.countplot(data=df, x = 'Sex',hue='HeartDisease')

"""**Insights**


*   Majority are Females
*   Males have more Heart Disease than females

###Heart Disease among different Race
"""

sns.set_style('darkgrid')
plt.figure(figsize=(15,6))
sns.countplot(data=df, x = 'Race',hue='HeartDisease')
plt.show()

"""**Insights**


*   Majority peoples are White
*   Also, most heart disease patients are white people

###Age Category wise heart disease
"""

adata = df.sort_values(by=['AgeCategory'],ascending = True)
plt.figure(figsize=(10,6))
sns.histplot(data=adata, x="AgeCategory", hue="HeartDisease", multiple="stack")
plt.xticks(rotation=30)
plt.show()

"""**Insights**


*   People who have heart disease, are mostly old people

###Peoples describe their general health condition
"""

plt.figure(figsize=(10,6))
sns.countplot(data=df, x = 'GenHealth',hue='Sex')

"""**Insights**
*  Most people describe their general health as Very good, and the ration of females are higher than males. 

"""

"""##Data Preprocessing

###Missing Value Handling
"""

sns.set(rc = {'figure.figsize':(12,6)})
sns.heatmap(df.isnull(),cbar=False)

"""There are no missing values

###Encoding Categorical Values
"""

from sklearn.preprocessing import OrdinalEncoder
categorical_col = df.select_dtypes(include=['object']).columns
ordEncoder = OrdinalEncoder()
df[categorical_col] = ordEncoder.fit_transform(df[categorical_col])

df.head()

df.describe()

"""###Correlation"""

sns.set(rc = {'figure.figsize':(15,6)})
sns.heatmap(df.corr(),annot=True,cmap='coolwarm')

"""###Dataset Balancing"""

disease = df.groupby('HeartDisease').size()
disease

"""Here we can see the dataset is highly imbalanced. """

X = df.drop('HeartDisease',axis=1)
y = df['HeartDisease']

y.value_counts()

from imblearn import over_sampling
from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X,y)

y_resampled.value_counts()

"""#Machine Learning """

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix

X_train, X_test, y_train, y_test = train_test_split(X_resampled,y_resampled, test_size=0.3, random_state=42)

"""###Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)
predictions = dtree.predict(X_test)
print (classification_report(y_test,predictions))

filename = 'heart_disease_pred_model'
pickle.dump(dtree,open(filename,'wb'))

"""###Random Forest Classifier"""

"""from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=200)
rfc.fit(X_train, y_train)
rfc_prediction = rfc.predict(X_test)
print (classification_report(y_test,rfc_prediction))"""



"""Save the Random Forest Classifier model"""
#filename = 'heart_disease_pred_model'
#pickle.dump(rfc,open(filename,'wb'))

"""Save the Random Forest Classifier model using joblib"""
#joblib.dump(rfc,"heart_disease_pred_model.pkl")


"""#Conclusions

Accuracy

1.   Decision Tree Classifier: 95% 
2.   Random Forest Classifier: 96%
"""

